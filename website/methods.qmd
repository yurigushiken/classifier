---
title: "Methods"
---

## Data Source

- **Corpus:** CHILDES / TalkBank (MacWhinney, 2000)
- **Access:** childes-db (Sanchez et al., 2019), programmatic SQL access
- **Database version:** 2021.1
- **Language:** Mandarin Chinese (zho). Excludes Cantonese (yue) and Min Nan (nan)
- **Collection filter:** `collection_name = 'Chinese'` (monolingual only)


## Phase 1: Corpus Inventory

Enumerated all 39 Chinese-language corpora in CHILDES via childes-db. Collected per-corpus metadata: transcript counts, utterance counts, speaker codes, age ranges, and classifier token frequencies.


## Phase 2: Deterministic Extraction

### Target Classifiers (34)

个, 条, 只, 本, 张, 位, 头, 件, 年, 次, 天, 元, 下, 块, 岁, 名, 句, 家, 片, 份, 分, 部, 场, 把, 根, 颗, 辆, 种, 笔, 群, 对, 架, 组, 碗

### Extraction Logic

For each classifier token in the corpus, the immediately preceding token is checked. If the preceding token's POS tag is `num*` (numeral), `det` (determiner), or `pro:dem` (demonstrative pronoun), the row is included.

```sql
-- Core join logic
SELECT ...
FROM token c
JOIN token p
    ON p.utterance_id = c.utterance_id
   AND p.token_order = c.token_order - 1
JOIN utterance u ON u.id = c.utterance_id
JOIN transcript t ON t.id = c.transcript_id
WHERE ... AND c.gloss IN (classifier_list)
```

### Output: 70,655 rows from 18 corpora


## Phase 3: LLM-Assisted Annotation

### Model Selection

| Model | Provider | Result |
|-------|----------|--------|
| DeepSeek v3.2-speciale | OpenRouter | **Recommended for production** |
| GPT-5.2-Codex | OpenRouter | Equivalent QA/completeness on pilot samples. Minor adj-in-noun issue |
| Kimi k2.5 | OpenRouter | Equivalent QA/completeness on pilot samples |

: {.striped}

All models scored **20/20 clean** on both the focused validation sample (20 rows with high-risk cases) and a random sample (20 rows). DeepSeek recommended for production based on cleanest noun identification and consistent English rationales. The full 70,655-row production run is pending PI approval.

### Parameters

- **Temperature:** 0.3 (lowered from 1.0 after inconsistency on borderline nouns)
- **Reasoning:** `effort = "medium"` (resolved 3/20 malformed rows from v3)
- **Response format:** JSON with enforced schema
- **Concurrency:** asyncio.Semaphore, MAX_CONCURRENT = 10


### Prompt Design (5 iterations)

::: {.callout-note collapse="true"}
## Expand: Prompt Iteration History

| Version | Changes | Result |
|---------|---------|--------|
| v1 | Initial few-shot + JSON schema | 2/20 list outputs, mixed noun format |
| v2 | Added Focus Constraint + noun standardization | 20/20 clean |
| v3 | Demonstrative-copula rule, dual CL columns, compound nouns, rationale cap. Temp lowered to 0.3 | 17/20 clean (3 malformed on multi-noun) |
| v4 | Added reasoning.effort="medium". Benchmarked 3 models. | All models: 20/20 clean on both samples |
| v5 | Added Rule 6: flag_for_review + flag_reason with 4 narrow trigger conditions. 5th few-shot example (flagged). | 20/20 clean, 2/20 flagged (10%) |

: {.striped}
:::

### Key Prompt Features (Final v5)

1. **Six numbered analysis rules** covering noun identification, convention lookup, classifier type, overuse judgment, demonstrative-copula disambiguation, and human review flagging
2. **Compound noun instruction:** treat multi-morpheme nouns as units (图画书 not 书)
3. **Focus constraint:** analyze only the specific target classifier instance following the specified Preceding Word
4. **Dual output format:** `conventional_classifier` (pinyin) + `conventional_classifier_zh` (Chinese)
5. **Five few-shot examples** matching actual input format (Chinese + POS tags), including one flagged example
6. **One-sentence rationale cap**
7. **Human review flags** with 4 narrow trigger conditions: colloquial_tolerance, disputed_convention, implicit_noun_inference, multi_instance_disambiguation

### Output Schema

| Field | Description |
|-------|-------------|
| `identified_noun` | The noun modified by the classifier (Simplified Chinese), or `OMITTED` |
| `conventional_classifier` | Standard adult classifier (pinyin) |
| `conventional_classifier_zh` | Standard adult classifier (Simplified Chinese) |
| `classifier_type` | `General` (个) or `Specific` |
| `overuse_of_ge` | True if 个 was used where a specific classifier is conventional |
| `specific_semantic_class` | Deterministic classifier semantic class from token lookup (e.g., general, animacy, shape, temporal_event) |
| `rationale` | One-sentence explanation |
| `flag_for_review` | True if the row warrants human verification |
| `flag_reason` | Reason code: colloquial_tolerance, disputed_convention, implicit_noun_inference, or multi_instance_disambiguation |

: {.striped .hover}


## Schema Crosswalk (PI Design -> Current Pipeline)

The table below maps the [original PI spreadsheet](https://docs.google.com/spreadsheets/d/1Z01s1mhecqIbP28sWWG-SP5LWnf0SVxzIpq6NXMU3Sw/edit?usp=drive_link) to the current reproducible schema.

| Original PI Column | Current Field(s) | Notes |
|---|---|---|
| `filename` | `File Name` | Same meaning (CHILDES transcript path). |
| `line` | `utterance_order`, `classifier_token_order` | More precise than a single line number. |
| `utterance` | `Utterance` | Same meaning. |
| `个, 条, 只, ... , 碗` (wide classifier columns) | `Classifier` (long format) | Long format is canonical. Each row = one classifier instance. |
| `total_clf` | Derived from `utterance_id` grouping | Computable deterministically as count per utterance. |
| `Age` | `Age`, `age_years`, `age_available` | `Age` is original days. Years and missingness are computed fields. |
| `%gra` | `%gra` | Same meaning (POS sequence). |
| `Determiner/Numbers` | `Determiner/Numbers`, `determiner_type` | Added typed semantic label for analysis. |
| `Classifier` | `Classifier` | Same meaning. |
| `Classfifier type` | `classifier_type` (canonical), `Classifier type` (legacy) | Canonical snake_case + compatibility legacy column. |
| `Which type of specific` | `specific_semantic_class` | Deterministic classifier-semantic taxonomy (not LLM-derived). |
| `Oever use of Ge` | `overuse_of_ge` (canonical), `Over use of Ge...` (legacy) | Canonical snake_case + compatibility legacy column. |
| `Conventional classifiers` | `conventional_classifier`, `conventional_classifier_zh` | Pinyin + Simplified Chinese forms. |
| `Paired nouns` | `identified_noun` | Noun linked to target classifier, or `OMITTED`. |
| `Meaning` | `rationale` | One-sentence LLM explanation. |

: {.striped .hover}


## Estimated Cost

Based on three 20-row pilot runs (60 API calls total) with DeepSeek v3.2-speciale via OpenRouter:

| Metric | Value |
|--------|-------|
| Mean cost per row | $0.0019 |
| Pilot total (60 rows) | $0.11 |
| Estimated full run (70,655 rows) | $120 to $140 |
| With retry/re-run overhead | $135 to $155 |

: {.striped}

Per-row cost varies slightly by utterance length and reasoning complexity. The estimate uses the mean across all pilot runs, including cost spikes on longer utterances.


## Human Verification

All LLM-annotated results will require human verification. The `flag_for_review` column identifies rows that are most likely to need attention, based on four trigger conditions (colloquial tolerance, disputed convention, implicit noun inference, multi-instance disambiguation). However, flagged rows are a prioritization aid, not a substitute for reviewing the full dataset. Unflagged rows may still contain errors that fall outside the trigger conditions.


## Known Limitations

::: {.callout-warning}
## Limitations to Discuss

1. **No ground-truth lookup table.** The LLM relies on its own knowledge of conventional classifiers, which may vary for borderline nouns (e.g., 杯子, 肉圆, 怪物).

2. **Non-个 misuse undetected.** `overuse_of_ge` only captures overuse of the general classifier. A child using the wrong specific classifier (e.g., 只 for 笔 instead of 支) is marked `overuse_of_ge = False`.

3. **Multi-instance ambiguity.** When an utterance contains multiple instances of the same Preceding Word + Classifier pair, the model may select either instance.

4. **No formal inter-annotator agreement yet.** Current evaluation is consistency and format QA (20/20 JSON completeness on two samples). Formal human-annotated agreement scoring is planned for a subsequent validation phase.
:::


## Manuscript Methods Draft (Working)

*The following is a draft of the methods section for the manuscript. All numbers and procedures below reflect the current state of the pipeline as of February 2026. It is intended as a starting point for PI revision.*

### Data

Classifier contexts were drawn from the monolingual Mandarin Chinese corpora in the Child Language Data Exchange System (CHILDES, MacWhinney, 2000), accessed programmatically through childes-db version 2021.1 (Sanchez et al., 2019). All corpora in the Chinese collection were included. Cantonese and Min Nan corpora were excluded.

### Extraction

We identified 34 target numeral classifiers based on frequency in the corpus and relevance to the acquisition literature (Erbaugh, 1986). For each occurrence of a target classifier, we extracted the row if the immediately preceding token carried a numeral, determiner, or demonstrative pronoun part-of-speech tag. This deterministic filter yielded 70,655 classifier contexts from 18 corpora, spanning ages 1.2 to 10.5 years (mean 4.2, median 4.0). Target children produced 37% of classifier contexts, with the remainder from adult speakers (mothers, investigators, teachers, and others). Age metadata was missing for 12.4% of rows, primarily from the ZhouAssessment and LiZhou corpora.

Each row was assigned a computed determiner type (demonstrative, numeral, interrogative, ordinal, or quantifier) and a deterministic classifier semantic class (e.g., general, animacy, shape, artifact function, temporal event) based on the classifier token.

### LLM-Assisted Annotation

Each classifier context was annotated using DeepSeek v3.2-speciale, a large language model accessed via the OpenRouter API (temperature = 0.3, reasoning effort = medium). The model was prompted to identify the noun modified by the target classifier, determine the conventional adult classifier for that noun, classify the classifier as General (个) or Specific, and judge whether overuse of the general classifier 个 had occurred. When the noun was absent or only implicitly understood from context, the model returned OMITTED. A demonstrative-copula rule instructed the model to return OMITTED for constructions such as 这个是X, where the classifier modifies an implicit referent rather than the predicate noun.

The prompt was developed over five iterations, evaluated on a focused validation sample of 20 high-risk rows and a separate random sample of 20 rows. The final prompt included six analysis rules, five few-shot examples matching the actual input format (Chinese text with POS tags), a focus constraint restricting annotation to the specific target classifier instance, and a one-sentence rationale cap. Each row was also assigned a human review flag triggered by four narrow conditions: colloquial tolerance (个 is technically non-standard but widely accepted), disputed convention (genuine ambiguity about which classifier is standard), implicit noun inference (noun inferred from context rather than explicitly spoken), and multi-instance disambiguation (multiple identical classifier phrases in one utterance). Three candidate models (DeepSeek v3.2-speciale, GPT-5.2-Codex, and Kimi k2.5) all achieved 20/20 format completeness on both validation samples. DeepSeek was selected for production based on the cleanest noun identification and most consistent English-language rationales.

All LLM-annotated results will undergo human verification. The flag-for-review column prioritizes rows most likely to require attention, but unflagged rows may still contain errors that fall outside the trigger conditions. Formal inter-annotator agreement scoring is planned for a subsequent validation phase.


## References

- MacWhinney, B. (2000). *The CHILDES Project: Tools for Analyzing Talk*. Lawrence Erlbaum Associates.
- Sanchez, A., Meylan, S. C., Braginsky, M., MacDonald, K. E., Yurovsky, D., & Frank, M. C. (2019). childes-db: A flexible and reproducible interface to the Child Language Data Exchange System. *Behavior Research Methods*, 51(4), 1928-1941.
- Erbaugh, M. S. (1986). Taking stock: The development of Chinese noun classifiers historically and in young children. In C. Craig (Ed.), *Noun Classes and Categorization* (pp. 399-436). John Benjamins.
